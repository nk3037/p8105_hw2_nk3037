P8105 HW2 nk3037
================
Navya Koneripalli
2023-10-01

# Question 1

### Cleaning pols-month.csv

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month = month.name
  )

pols_month_data = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -prez_dem, -prez_gop)
```

### Cleaning snp.csv

``` r
snp_data = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month])
```

### Cleaning unemployment.csv

``` r
unemployment_data =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  rename(year = Year) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  )
```

### Merging pols_month_data, snp_data and unemployment_data

``` r
merged_data =
  pols_month_data %>% 
  left_join(snp_data) %>% 
  left_join(unemployment_data)
```

The `merged_data` dataset contains 822 rows and 13 columns.

The `pols_month_data` has data on the political party association of the
president, governors and senators for a given year. The dataset contains
822 rows and 10 columns. It contains data from the years 1947 to 2015.

The `snp_data` dataset contains data related to the S&P stock market
index. It contains 787 rows and 4 columns.It has data for the year 1 to
12.

Lastly, the `unemployment_data` dataset contains data on the monthly
unemployment rate. It has 816 rows and 3 columns for the years 1948 to
2015.

# Question 2

### Data manipulation for Mr. Trash Wheel dataset

``` r
mr_trash_wheel = 
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586")
mr_trash_wheel = janitor::clean_names(mr_trash_wheel, case = "snake") %>% #convert all variable names into snake_case

mutate(homes_powered = (weight_tons * (500/30)))
# Calculated the average number of homes powered for each tonne of trash and applied the formula to all the rows of the Mr. Trash Wheel dataset

mr_trash_wheel$year = as.numeric(mr_trash_wheel$year)
# Converting the character year variable into a numeric one so that it can be binded with the year variables from the other datasets

mr_trash_wheel = mr_trash_wheel%>% 
  mutate(trash_wheel_name = "Mr. Trash Wheel")
# Added an additional variable trash_wheel_name to help with the final bind of the datasets

mr_trash_wheel = mr_trash_wheel %>% 
  select(-sports_balls, -glass_bottles)
# removed columns so that the number and column headings match with the other two datasets for ease of binding
```

### Data manipulation for Professor Trash Wheel dataset

``` r
prof_trash_wheel =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108")
prof_trash_wheel = janitor::clean_names(prof_trash_wheel, case = "snake") %>% #convert all variable names into snake_case

mutate(homes_powered = (weight_tons * (500/30)))
# Calculated the average number of homes powered for each tonne of trash and applied the formula to all the rows of the Professor Trash Wheel dataset

prof_trash_wheel = prof_trash_wheel%>% 
  mutate(trash_wheel_name = "Professor Trash Wheel")
# Added an additional variable trash_wheel_name to help with the final bind of the datasets

prof_trash_wheel = prof_trash_wheel %>% 
  select(-glass_bottles)
# removed column so that the number and column headings match with the other two datasets for ease of binding
```

### Data manipulation for Gwynnda Trash Wheel dataset

``` r
gwynnda_trash_wheel =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157")
gwynnda_trash_wheel = janitor::clean_names(gwynnda_trash_wheel, case = "snake") %>% #convert all variable names into snake_case

mutate(homes_powered = (weight_tons * (500/30)))
# Calculated the average number of homes powered for each tonne of trash and applied the formula to all the rows of the Gwynnda Trash Wheel dataset

gwynnda_trash_wheel = gwynnda_trash_wheel%>% 
  mutate(trash_wheel_name = "Gwynnda Trash Wheel")
# Added an additional variable trash_wheel_name to help with the final bind of the datasets
```

### Merging Mr. Trash Wheel, Prof. Trash Wheel and Gwynnda Trash Wheel datasets

``` r
merged_trash_wheel_part1 = rbind(mr_trash_wheel, prof_trash_wheel)
merged_trash_wheel = rbind(merged_trash_wheel_part1, gwynnda_trash_wheel)
# binded the three datasets on top of each other

filtered_mr_trash = merged_trash_wheel %>% 
  filter(trash_wheel_name == "Mr. Trash Wheel")
# filtered the dataset to contain only Mr. Trash Wheel to calculate the sum of weight of trash collected.

filtered_gwynnda = merged_trash_wheel %>% 
  filter(trash_wheel_name == "Gwynnda Trash Wheel" & month == "July" & year == "2021")
# filtered the dataset to contain only Gwynnda Trash Wheel in July 2021 to calculate the sum of cigarettes collected.
```

The `merged_trash_wheel` dataset contains 845 rows and 13 columns.

The merged dataset contains trash collection data for the years between
2014 and 2023.

The `merged_trash_wheel`dataset captures the weight (in tons), volume
and count of each individual type of waste collected by each of the 3
trash wheels by dumpster number.

The average weight of trash collected by all of the trash wheels across
the full time period of the dataset is 3.0094793 tons.

The total weight of trash collected by Mr. Trash Wheel is 1875.1 tons.

The total number of cigarettes collected by Gwynnda Trash Wheel in July
2021 is 1.158222^{7} cigarette butts.
