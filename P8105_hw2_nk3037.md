P8105 HW2 nk3037
================
Navya Koneripalli
2023-10-01

# Question 1

### Cleaning pols-month.csv

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month = month.name
  )

pols_month_data = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -prez_dem, -prez_gop)
```

### Cleaning snp.csv

``` r
snp_data = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month])
```

### Cleaning unemployment.csv

``` r
unemployment_data =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  rename(year = Year) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  )
```

### Merging pols_month_data, snp_data and unemployment_data

``` r
merged_data =
  pols_month_data %>% 
  left_join(snp_data) %>% 
  left_join(unemployment_data)
```

The `merged_data` dataset contains 822 rows and 13 columns.

The `pols_month_data` has data on the political party association of the
president, governors and senators for a given year. The dataset contains
822 rows and 10 columns. It contains data from the years 1947 to 2015.

The `snp_data` dataset contains data related to the S&P stock market
index. It contains 787 rows and 4 columns.It has data for the year 1 to
12.

Lastly, the `unemployment_data` dataset contains data on the monthly
unemployment rate. It has 816 rows and 3 columns for the years 1948 to
2015.

# Question 2

### Data manipulation for Mr. Trash Wheel dataset

``` r
mr_trash_wheel = 
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586")
mr_trash_wheel = janitor::clean_names(mr_trash_wheel, case = "snake") %>% #convert all variable names into snake_case

mutate(homes_powered = (weight_tons * (500/30)))
# Calculated the average number of homes powered for each tonne of trash and applied the formula to all the rows of the Mr. Trash Wheel dataset

mr_trash_wheel$year = as.numeric(mr_trash_wheel$year)
# Converting the character year variable into a numeric one so that it can be binded with the year variables from the other datasets

mr_trash_wheel = mr_trash_wheel%>% 
  mutate(trash_wheel_name = "Mr. Trash Wheel")
# Added an additional variable trash_wheel_name to help with the final bind of the datasets

mr_trash_wheel = mr_trash_wheel %>% 
  select(-sports_balls, -glass_bottles)
# removed columns so that the number and column headings match with the other two datasets for ease of binding
```

### Data manipulation for Professor Trash Wheel dataset

``` r
prof_trash_wheel =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108")
prof_trash_wheel = janitor::clean_names(prof_trash_wheel, case = "snake") %>% #convert all variable names into snake_case

mutate(homes_powered = (weight_tons * (500/30)))
# Calculated the average number of homes powered for each tonne of trash and applied the formula to all the rows of the Professor Trash Wheel dataset

prof_trash_wheel = prof_trash_wheel%>% 
  mutate(trash_wheel_name = "Professor Trash Wheel")
# Added an additional variable trash_wheel_name to help with the final bind of the datasets

prof_trash_wheel = prof_trash_wheel %>% 
  select(-glass_bottles)
# removed column so that the number and column headings match with the other two datasets for ease of binding
```

### Data manipulation for Gwynnda Trash Wheel dataset

``` r
gwynnda_trash_wheel =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157")
gwynnda_trash_wheel = janitor::clean_names(gwynnda_trash_wheel, case = "snake") %>% #convert all variable names into snake_case

mutate(homes_powered = (weight_tons * (500/30)))
# Calculated the average number of homes powered for each tonne of trash and applied the formula to all the rows of the Gwynnda Trash Wheel dataset

gwynnda_trash_wheel = gwynnda_trash_wheel%>% 
  mutate(trash_wheel_name = "Gwynnda Trash Wheel")
# Added an additional variable trash_wheel_name to help with the final bind of the datasets
```

### Merging Mr. Trash Wheel, Prof. Trash Wheel and Gwynnda Trash Wheel datasets

``` r
merged_trash_wheel_part1 = rbind(mr_trash_wheel, prof_trash_wheel)
merged_trash_wheel = rbind(merged_trash_wheel_part1, gwynnda_trash_wheel)
# binded the three datasets on top of each other

filtered_mr_trash = merged_trash_wheel %>% 
  filter(trash_wheel_name == "Mr. Trash Wheel")
# filtered the dataset to contain only Mr. Trash Wheel to calculate the sum of weight of trash collected.

filtered_gwynnda = merged_trash_wheel %>% 
  filter(trash_wheel_name == "Gwynnda Trash Wheel" & month == "July" & year == "2021")
# filtered the dataset to contain only Gwynnda Trash Wheel in July 2021 to calculate the sum of cigarettes collected.
```

The `merged_trash_wheel` dataset contains 845 rows and 13 columns.

The merged dataset contains trash collection data for the years between
2014 and 2023.

The `merged_trash_wheel`dataset captures the weight (in tons), volume
and count of each individual type of waste collected by each of the 3
trash wheels by dumpster number.

The average weight of trash collected by all of the trash wheels across
the full time period of the dataset is 3.0094793 tons.

The total weight of trash collected by Mr. Trash Wheel is 1875.1 tons.

The total number of cigarettes collected by Gwynnda Trash Wheel in July
2021 is 1.158222^{7} cigarette butts.

# Question 3

### Data manipulation of mci_baseline data

``` r
mci_baseline =
  read_csv("./data/data_mci/MCI_baseline.csv", skip = 1) #reading the .csv file into R
mci_baseline = janitor::clean_names(mci_baseline, case = "snake") # convert all variable names into snake_case

mci_baseline = mci_baseline %>% 
  mutate(
    sex = recode(sex, "1" = "Male", "0" = "Female"), 
    apoe4_status = recode(apoe4, "1" = "Carrier", "0" = "Non-carrier")
    ) #recoded the sex and apoe4_status to non-numeric variable types

mci_baseline$age_at_onset = as.numeric(mci_baseline$age_at_onset) # converted the age_at_onset variable from character to numeric so that the dataset can be filtered in the next step

mci_baseline_excluded = mci_baseline %>% 
  filter((age_at_onset - current_age) > 0)
# removing the patients that do not meet the requirements
```

The `mci_baseline` dataset contains the data of 483 patients. Of this,
93 patients had developed MCI. The average age of the patients was
65.0467909 years. The dataset contained 211 females. Among the women, 63
were carriers. Of the females, 45 developed MCI.

### Data manipulation of mci_amyloid data

``` r
mci_amyloid = 
  read.csv("./data/data_mci/mci_amyloid.csv", skip = 1) #reading the .csv file into R
mci_amyloid = janitor::clean_names(mci_amyloid, case = "snake") # convert all variable names into snake_case

mci_amyloid = mci_amyloid %>%
  rename(baseline_post_2hrs= time_2) %>% 
  rename (baseline_post_4hrs= time_4) %>% 
  rename(baseline_post_6hrs= time_6) %>% 
  rename(baseline_post_8hrs= time_8)
#renamed the columns to be more descriptive of the variable

mci_amyloid = mci_amyloid %>% 
  rename(id = study_id)
#renamed the id variable so that it is consistent with mci_baseline

columns_to_convert <- c("baseline", "baseline_post_2hrs", "baseline_post_4hrs", "baseline_post_6hrs", "baseline_post_8hrs")

mci_amyloid[columns_to_convert] <- lapply(mci_amyloid[columns_to_convert], as.numeric)
# convert the variable types into numeric
```

The `mci_amyloid` dataset contains the data of 487 patients and
6columns. Of this, 487 patients had MCI at baseline.

The average baseline amyloid ratio is 0.1109638.

The average amyloid ratio 2 hours post baseline is 0.1102838.

The average amyloid ratio 4 hours post baseline is 0.1099878.

The average amyloid ratio 6 hours post baseline is 0.1089017.

The average amyloid ratio 8 hours post baseline is 0.1082381.

### Merge the baseline_excluded and amyloid datasets

``` r
merged_mci_data = inner_join(mci_baseline_excluded, mci_amyloid, by = "id")
#Joined the two datasets by "id" variable for the patients that appear in both mci_baseline_excluded and mci_amyloid_excluded datasets
merged_mci_data = merged_mci_data %>% 
  select(-apoe4)
# removed the repeating apoe4 column
merged_mci_data = merged_mci_data %>% 
  filter(is.na(baseline)|(age_at_onset - current_age) > 0)
# removing the patints that do not meet the requirements
anti_merged_mci_data <- anti_join(mci_baseline_excluded, mci_amyloid, by = "id")
# anti-merged the two datasets to find which patients are in one dataset but not the other
```

The `merged_mci_data` dataset contains 90 rows and 11 columns. There are
59 carriers. The `merged_mci_data` has 43 females and 47 males.

The average age of the patients is 65.6766667 years. The ages of the
patients range from 58.1 to 71.6 years.

The average years of education of the patients is 16.4888889 years.

The average age of onset of MCI for the patients is 70.5077778 years.

There are 3 patients who are in the mci_baseline dataset and not in the
mci_amyloid dataset. This is because these patients have a current age
that is less than the recorded age of onset of MCI, which is not
possible.

### Export the merged_mci_data to .csv

``` r
write.csv(merged_mci_data, file = "p8105_hw2_nk3037_merged_mci_data.csv", row.names = FALSE)
#exported the dataset as a csv file
```
